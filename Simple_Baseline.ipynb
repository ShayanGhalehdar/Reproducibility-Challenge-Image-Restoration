{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BVNR60tftmcf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LayerNorm2d(nn.Module):\n",
        "    def __init__(self, num_channels, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(num_channels, eps=eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute (N, C, H, W) -> (N, H, W, C), apply LayerNorm, then permute back\n",
        "        return self.norm(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=2):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = self.pool(x)\n",
        "        attn = self.conv1(attn)\n",
        "        attn = self.relu(attn)\n",
        "        attn = self.conv2(attn)\n",
        "        attn = self.sigmoid(attn)\n",
        "        return x * attn\n",
        "\n",
        "class BaselineBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(BaselineBlock, self).__init__()\n",
        "        self.norm1 = LayerNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.dconv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.ca = ChannelAttention(in_channels)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "\n",
        "        self.norm2 = LayerNorm2d(in_channels)\n",
        "        self.conv3 = nn.Conv2d(in_channels, 2 * in_channels, kernel_size=1)\n",
        "        self.conv4 = nn.Conv2d(2 * in_channels, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.norm1(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.dconv(out)\n",
        "        out = self.gelu(out)\n",
        "        out = self.ca(out)\n",
        "        out = self.conv2(out)\n",
        "        out += residual\n",
        "\n",
        "        residual = out\n",
        "\n",
        "        out = self.norm2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.gelu(out)\n",
        "        out = self.conv4(out)\n",
        "        out += residual\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "X = torch.rand((1, 32, 256, 256))\n",
        "model = BaselineBlock(32)\n",
        "Y = model(X)\n",
        "print(Y.shape)  # Expected: (1, 3, 256, 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cViizVwNi9uj",
        "outputId": "14793db1-c5cb-4349-a44d-d3e85832256e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, n_channels=3, width=32):\n",
        "        super(BaselineModel, self).__init__()\n",
        "        self.init_conv = nn.Conv2d(n_channels, width, kernel_size=3, padding=1)\n",
        "\n",
        "        # Encoder (Downsampling path)\n",
        "        self.enc1 = self._make_stage(width, 4)\n",
        "        self.down1 = nn.Conv2d(width, width, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.enc2 = self._make_stage(width, 4)\n",
        "        self.down2 = nn.Conv2d(width, width, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.enc3 = self._make_stage(width, 4)\n",
        "        self.down3 = nn.Conv2d(width, width, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.enc4 = self._make_stage(width, 4)\n",
        "        self.down4 = nn.Conv2d(width, width, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self._make_stage(width, 4)\n",
        "\n",
        "        # Decoder (Upsampling path)\n",
        "        self.up4 = self._upsample_layer(width)\n",
        "        self.dec4 = self._make_stage(width, 4)\n",
        "\n",
        "        self.up3 = self._upsample_layer(width)\n",
        "        self.dec3 = self._make_stage(width, 4)\n",
        "\n",
        "        self.up2 = self._upsample_layer(width)\n",
        "        self.dec2 = self._make_stage(width, 4)\n",
        "\n",
        "        self.up1 = self._upsample_layer(width)\n",
        "        self.dec1 = self._make_stage(width, 4)\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(width, n_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def _make_stage(self, channels, num_blocks):\n",
        "        \"\"\"Helper function to create multiple BaselineBlocks.\"\"\"\n",
        "        return nn.Sequential(*[BaselineBlock(channels) for _ in range(num_blocks)])\n",
        "\n",
        "    def _upsample_layer(self, channels):\n",
        "        \"\"\"Upsample using pointwise convolution followed by pixel shuffle.\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(channels, channels * 4, kernel_size=1),\n",
        "            nn.PixelShuffle(2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        x = self.down1(e1)\n",
        "\n",
        "        e2 = self.enc2(x)\n",
        "        x = self.down2(e2)\n",
        "\n",
        "        e3 = self.enc3(x)\n",
        "        x = self.down3(e3)\n",
        "\n",
        "        e4 = self.enc4(x)\n",
        "        x = self.down4(e4)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up4(x) + e4\n",
        "        x = self.dec4(x)\n",
        "\n",
        "        x = self.up3(x) + e3\n",
        "        x = self.dec3(x)\n",
        "\n",
        "        x = self.up2(x) + e2\n",
        "        x = self.dec2(x)\n",
        "\n",
        "        x = self.up1(x) + e1\n",
        "        x = self.dec1(x)\n",
        "\n",
        "        # Final output\n",
        "        x = self.final_conv(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zkyscXw65HnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "X = torch.rand((10, 3, 256, 256))\n",
        "model = BaselineModel(3, 32)\n",
        "Y = model(X)\n",
        "print(Y.shape)  # Expected: (10, 3, 256, 256)"
      ],
      "metadata": {
        "id": "LPC9dCfy8_Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567c9a1d-cb53-4fd8-a4f1-1cc945c79ad6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 256, 256])\n"
          ]
        }
      ]
    }
  ]
}